INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 6600; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local440030644_0001_m_000142_0 is done. And is in the process of committing%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #606%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #606%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 31ms%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local440030644_0001_m_000142_0' done.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local440030644_0001_m_000142_0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local440030644_0001_m_000143_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.SortedRanges - currentIndex 0   0:0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - mapreduce.cluster.local.dir for child : /tmp/hadoop-gaoch/mapred/local/localRunner//root/jobcache/job_local440030644_0001/attempt_local440030644_0001_m_000143_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - using new api for output committer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@47b99f7c%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9001/TestWordCountOutput/File_input-Test-CANA-482590newsML.txt-r-00000:0+428%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #607%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #607%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=428
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743334_2510; getBlockSize()=428; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743334_2510; getBlockSize()=428; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #608%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #608%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=428
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743334_2510; getBlockSize()=428; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743334_2510; getBlockSize()=428; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 127.0.0.1:50010%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - %INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 5808; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214224(104856896); length = 173/6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0%INFO main org.apache.hadoop.mapreduce.Job -  map 84% reduce 0%%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local440030644_0001_m_000143_0 is done. And is in the process of committing%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #609%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #609%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 0ms%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local440030644_0001_m_000143_0' done.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local440030644_0001_m_000143_0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local440030644_0001_m_000144_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.SortedRanges - currentIndex 0   0:0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - mapreduce.cluster.local.dir for child : /tmp/hadoop-gaoch/mapred/local/localRunner//root/jobcache/job_local440030644_0001/attempt_local440030644_0001_m_000144_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - using new api for output committer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@f4d33f0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9001/TestWordCountOutput/File_input-Test-CANA-485385newsML.txt-r-00000:0+405%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #610%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #610%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=405
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743359_2535; getBlockSize()=405; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743359_2535; getBlockSize()=405; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #611%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #611%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=405
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743359_2535; getBlockSize()=405; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743359_2535; getBlockSize()=405; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 127.0.0.1:50010%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - %INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 5544; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214232(104856928); length = 165/6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local440030644_0001_m_000144_0 is done. And is in the process of committing%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #612%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #612%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 0ms%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local440030644_0001_m_000144_0' done.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local440030644_0001_m_000144_0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local440030644_0001_m_000145_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.SortedRanges - currentIndex 0   0:0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - mapreduce.cluster.local.dir for child : /tmp/hadoop-gaoch/mapred/local/localRunner//root/jobcache/job_local440030644_0001/attempt_local440030644_0001_m_000145_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - using new api for output committer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@66146219%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9001/TestWordCountOutput/File_input-Test-AUSTR-486633newsML.txt-r-00000:0+397%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #613%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #613%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=397
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743324_2500; getBlockSize()=397; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743324_2500; getBlockSize()=397; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #614%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #614%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=397
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743324_2500; getBlockSize()=397; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743324_2500; getBlockSize()=397; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 127.0.0.1:50010%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - %INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 5985; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214220(104856880); length = 177/6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local440030644_0001_m_000145_0 is done. And is in the process of committing%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #615%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #615%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 0ms%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local440030644_0001_m_000145_0' done.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local440030644_0001_m_000145_0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local440030644_0001_m_000146_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.SortedRanges - currentIndex 0   0:0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - mapreduce.cluster.local.dir for child : /tmp/hadoop-gaoch/mapred/local/localRunner//root/jobcache/job_local440030644_0001/attempt_local440030644_0001_m_000146_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - using new api for output committer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@63173352%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9001/TestWordCountOutput/File_input-Test-AUSTR-480313newsML.txt-r-00000:0+394%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #616%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #616%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=394
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743365_2541; getBlockSize()=394; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743365_2541; getBlockSize()=394; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #617%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #617%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=394
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743365_2541; getBlockSize()=394; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743365_2541; getBlockSize()=394; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 127.0.0.1:50010%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - %INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 5719; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214228(104856912); length = 169/6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local440030644_0001_m_000146_0 is done. And is in the process of committing%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #618%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #618%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 0ms%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local440030644_0001_m_000146_0' done.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local440030644_0001_m_000146_0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local440030644_0001_m_000147_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.SortedRanges - currentIndex 0   0:0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - mapreduce.cluster.local.dir for child : /tmp/hadoop-gaoch/mapred/local/localRunner//root/jobcache/job_local440030644_0001/attempt_local440030644_0001_m_000147_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - using new api for output committer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.%INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@17fcc987%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9001/TestWordCountOutput/File_input-Test-CANA-480836newsML.txt-r-00000:0+391%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #619%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #619%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=391
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743245_2421; getBlockSize()=391; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743245_2421; getBlockSize()=391; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #620%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #620%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=391
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743245_2421; getBlockSize()=391; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743245_2421; getBlockSize()=391; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 127.0.0.1:50010%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - %INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 6072; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214216(104856864); length = 181/6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local440030644_0001_m_000147_0 is done. And is in the process of committing%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #621%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #621%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 0ms%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local440030644_0001_m_000147_0' done.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local440030644_0001_m_000147_0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local440030644_0001_m_000148_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.SortedRanges - currentIndex 0   0:0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - mapreduce.cluster.local.dir for child : /tmp/hadoop-gaoch/mapred/local/localRunner//root/jobcache/job_local440030644_0001/attempt_local440030644_0001_m_000148_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - using new api for output committer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6df5a8c8%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9001/TestWordCountOutput/File_input-Test-AUSTR-488603newsML.txt-r-00000:0+388%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #622%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #622%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=388
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743238_2414; getBlockSize()=388; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743238_2414; getBlockSize()=388; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #623%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #623%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=388
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743238_2414; getBlockSize()=388; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743238_2414; getBlockSize()=388; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 127.0.0.1:50010%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - %INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 5320; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214240(104856960); length = 157/6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local440030644_0001_m_000148_0 is done. And is in the process of committing%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #624%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #624%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 0ms%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local440030644_0001_m_000148_0' done.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local440030644_0001_m_000148_0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local440030644_0001_m_000149_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.SortedRanges - currentIndex 0   0:0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - mapreduce.cluster.local.dir for child : /tmp/hadoop-gaoch/mapred/local/localRunner//root/jobcache/job_local440030644_0001/attempt_local440030644_0001_m_000149_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - using new api for output committer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@426efa54%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9001/TestWordCountOutput/File_input-Test-CANA-479853newsML.txt-r-00000:0+386%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #625%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #625%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=386
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743254_2430; getBlockSize()=386; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743254_2430; getBlockSize()=386; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #626%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #626%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=386
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743254_2430; getBlockSize()=386; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743254_2430; getBlockSize()=386; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 127.0.0.1:50010%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - %INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 5412; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214236(104856944); length = 161/6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local440030644_0001_m_000149_0 is done. And is in the process of committing%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #627%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #627%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 0ms%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local440030644_0001_m_000149_0' done.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local440030644_0001_m_000149_0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local440030644_0001_m_000150_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.SortedRanges - currentIndex 0   0:0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - mapreduce.cluster.local.dir for child : /tmp/hadoop-gaoch/mapred/local/localRunner//root/jobcache/job_local440030644_0001/attempt_local440030644_0001_m_000150_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - using new api for output committer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@529fb0f%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9001/TestWordCountOutput/File_input-Test-AUSTR-486144newsML.txt-r-00000:0+381%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #628%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #628%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=381
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743260_2436; getBlockSize()=381; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743260_2436; getBlockSize()=381; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #629%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #629%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=381
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743260_2436; getBlockSize()=381; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743260_2436; getBlockSize()=381; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 127.0.0.1:50010%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - %INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 5852; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214224(104856896); length = 173/6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local440030644_0001_m_000150_0 is done. And is in the process of committing%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #630%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #630%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 0ms%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local440030644_0001_m_000150_0' done.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local440030644_0001_m_000150_0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local440030644_0001_m_000151_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.SortedRanges - currentIndex 0   0:0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - mapreduce.cluster.local.dir for child : /tmp/hadoop-gaoch/mapred/local/localRunner//root/jobcache/job_local440030644_0001/attempt_local440030644_0001_m_000151_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - using new api for output committer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5b2b1549%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9001/TestWordCountOutput/File_input-Test-CANA-485058newsML.txt-r-00000:0+378%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #631%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #631%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=378
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743289_2465; getBlockSize()=378; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743289_2465; getBlockSize()=378; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #632%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #632%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=378
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743289_2465; getBlockSize()=378; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743289_2465; getBlockSize()=378; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 127.0.0.1:50010%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - %INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 5016; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214248(104856992); length = 149/6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local440030644_0001_m_000151_0 is done. And is in the process of committing%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #633%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #633%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 0ms%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local440030644_0001_m_000151_0' done.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local440030644_0001_m_000151_0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local440030644_0001_m_000152_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.SortedRanges - currentIndex 0   0:0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - mapreduce.cluster.local.dir for child : /tmp/hadoop-gaoch/mapred/local/localRunner//root/jobcache/job_local440030644_0001/attempt_local440030644_0001_m_000152_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - using new api for output committer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@24180979%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9001/TestWordCountOutput/File_input-Test-CANA-485382newsML.txt-r-00000:0+376%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #634%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #634%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=376
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743399_2575; getBlockSize()=376; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743399_2575; getBlockSize()=376; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #635%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #635%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=376
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743399_2575; getBlockSize()=376; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743399_2575; getBlockSize()=376; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 127.0.0.1:50010%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - %INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 5016; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214248(104856992); length = 149/6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local440030644_0001_m_000152_0 is done. And is in the process of committing%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #636%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #636%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 0ms%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local440030644_0001_m_000152_0' done.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local440030644_0001_m_000152_0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local440030644_0001_m_000153_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.SortedRanges - currentIndex 0   0:0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - mapreduce.cluster.local.dir for child : /tmp/hadoop-gaoch/mapred/local/localRunner//root/jobcache/job_local440030644_0001/attempt_local440030644_0001_m_000153_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - using new api for output committer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@56369a09%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9001/TestWordCountOutput/File_input-Test-CANA-481639newsML.txt-r-00000:0+374%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #637%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #637%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=374
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743284_2460; getBlockSize()=374; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743284_2460; getBlockSize()=374; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #638%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #638%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=374
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743284_2460; getBlockSize()=374; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743284_2460; getBlockSize()=374; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 127.0.0.1:50010%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - %INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 5280; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214240(104856960); length = 157/6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local440030644_0001_m_000153_0 is done. And is in the process of committing%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #639%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #639%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 0ms%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local440030644_0001_m_000153_0' done.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local440030644_0001_m_000153_0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local440030644_0001_m_000154_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.SortedRanges - currentIndex 0   0:0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - mapreduce.cluster.local.dir for child : /tmp/hadoop-gaoch/mapred/local/localRunner//root/jobcache/job_local440030644_0001/attempt_local440030644_0001_m_000154_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - using new api for output committer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@36f3e02f%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9001/TestWordCountOutput/File_input-Test-CANA-485066newsML.txt-r-00000:0+373%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #640%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #640%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=373
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743282_2458; getBlockSize()=373; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743282_2458; getBlockSize()=373; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #641%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #641%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=373
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743282_2458; getBlockSize()=373; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743282_2458; getBlockSize()=373; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 127.0.0.1:50010%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - %INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 4884; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214252(104857008); length = 145/6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0%INFO main org.apache.hadoop.mapreduce.Job -  map 90% reduce 0%%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local440030644_0001_m_000154_0 is done. And is in the process of committing%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #642%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #642%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 0ms%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local440030644_0001_m_000154_0' done.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local440030644_0001_m_000154_0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local440030644_0001_m_000155_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.SortedRanges - currentIndex 0   0:0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - mapreduce.cluster.local.dir for child : /tmp/hadoop-gaoch/mapred/local/localRunner//root/jobcache/job_local440030644_0001/attempt_local440030644_0001_m_000155_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - using new api for output committer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@492f2828%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9001/TestWordCountOutput/File_input-Test-AUSTR-486827newsML.txt-r-00000:0+372%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #643%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #643%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=372
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743343_2519; getBlockSize()=372; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743343_2519; getBlockSize()=372; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #644%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #644%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=372
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743343_2519; getBlockSize()=372; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743343_2519; getBlockSize()=372; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 127.0.0.1:50010%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - %INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 5719; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214228(104856912); length = 169/6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local440030644_0001_m_000155_0 is done. And is in the process of committing%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #645%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #645%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 0ms%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local440030644_0001_m_000155_0' done.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local440030644_0001_m_000155_0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local440030644_0001_m_000156_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.SortedRanges - currentIndex 0   0:0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - mapreduce.cluster.local.dir for child : /tmp/hadoop-gaoch/mapred/local/localRunner//root/jobcache/job_local440030644_0001/attempt_local440030644_0001_m_000156_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - using new api for output committer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1a887444%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9001/TestWordCountOutput/File_input-Test-CANA-486847newsML.txt-r-00000:0+361%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #646%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #646%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=361
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743232_2408; getBlockSize()=361; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743232_2408; getBlockSize()=361; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #647%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #647%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=361
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743232_2408; getBlockSize()=361; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743232_2408; getBlockSize()=361; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 127.0.0.1:50010%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - %INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 5016; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214248(104856992); length = 149/6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local440030644_0001_m_000156_0 is done. And is in the process of committing%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #648%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #648%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 0ms%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local440030644_0001_m_000156_0' done.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local440030644_0001_m_000156_0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local440030644_0001_m_000157_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.SortedRanges - currentIndex 0   0:0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - mapreduce.cluster.local.dir for child : /tmp/hadoop-gaoch/mapred/local/localRunner//root/jobcache/job_local440030644_0001/attempt_local440030644_0001_m_000157_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - using new api for output committer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7cc532b1%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9001/TestWordCountOutput/File_input-Test-CANA-486849newsML.txt-r-00000:0+361%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #649%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #649%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=361
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743370_2546; getBlockSize()=361; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743370_2546; getBlockSize()=361; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #650%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #650%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=361
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743370_2546; getBlockSize()=361; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743370_2546; getBlockSize()=361; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 127.0.0.1:50010%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - %INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 5016; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214248(104856992); length = 149/6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local440030644_0001_m_000157_0 is done. And is in the process of committing%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #651%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #651%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 0ms%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local440030644_0001_m_000157_0' done.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local440030644_0001_m_000157_0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local440030644_0001_m_000158_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.SortedRanges - currentIndex 0   0:0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - mapreduce.cluster.local.dir for child : /tmp/hadoop-gaoch/mapred/local/localRunner//root/jobcache/job_local440030644_0001/attempt_local440030644_0001_m_000158_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - using new api for output committer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1b6b397a%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9001/TestWordCountOutput/File_input-Test-AUSTR-480426newsML.txt-r-00000:0+360%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #652%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #652%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=360
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743244_2420; getBlockSize()=360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743244_2420; getBlockSize()=360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #653%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #653%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=360
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743244_2420; getBlockSize()=360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743244_2420; getBlockSize()=360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 127.0.0.1:50010%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - %INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 5187; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214244(104856976); length = 153/6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local440030644_0001_m_000158_0 is done. And is in the process of committing%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #654%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #654%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 0ms%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local440030644_0001_m_000158_0' done.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local440030644_0001_m_000158_0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local440030644_0001_m_000159_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.SortedRanges - currentIndex 0   0:0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - mapreduce.cluster.local.dir for child : /tmp/hadoop-gaoch/mapred/local/localRunner//root/jobcache/job_local440030644_0001/attempt_local440030644_0001_m_000159_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - using new api for output committer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.%INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@639ed626%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9001/TestWordCountOutput/File_input-Test-AUSTR-483311newsML.txt-r-00000:0+350%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #655%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #655%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=350
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743358_2534; getBlockSize()=350; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743358_2534; getBlockSize()=350; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #656%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #656%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=350
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743358_2534; getBlockSize()=350; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743358_2534; getBlockSize()=350; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 127.0.0.1:50010%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - %INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 5320; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214240(104856960); length = 157/6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local440030644_0001_m_000159_0 is done. And is in the process of committing%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #657%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #657%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 0ms%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local440030644_0001_m_000159_0' done.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local440030644_0001_m_000159_0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local440030644_0001_m_000160_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.SortedRanges - currentIndex 0   0:0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - mapreduce.cluster.local.dir for child : /tmp/hadoop-gaoch/mapred/local/localRunner//root/jobcache/job_local440030644_0001/attempt_local440030644_0001_m_000160_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - using new api for output committer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@d6951f4%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9001/TestWordCountOutput/File_input-Test-CANA-477890newsML.txt-r-00000:0+344%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #658%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #658%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=344
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743348_2524; getBlockSize()=344; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743348_2524; getBlockSize()=344; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #659%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #659%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=344
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743348_2524; getBlockSize()=344; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743348_2524; getBlockSize()=344; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 127.0.0.1:50010%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - %INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 4356; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214268(104857072); length = 129/6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local440030644_0001_m_000160_0 is done. And is in the process of committing%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #660%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #660%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 0ms%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local440030644_0001_m_000160_0' done.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local440030644_0001_m_000160_0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local440030644_0001_m_000161_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.SortedRanges - currentIndex 0   0:0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - mapreduce.cluster.local.dir for child : /tmp/hadoop-gaoch/mapred/local/localRunner//root/jobcache/job_local440030644_0001/attempt_local440030644_0001_m_000161_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - using new api for output committer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@516d3eb2%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9001/TestWordCountOutput/File_input-Test-AUSTR-483306newsML.txt-r-00000:0+342%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #661%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #661%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=342
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743298_2474; getBlockSize()=342; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743298_2474; getBlockSize()=342; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #662%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #662%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=342
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743298_2474; getBlockSize()=342; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743298_2474; getBlockSize()=342; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 127.0.0.1:50010%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - %INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 5453; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214236(104856944); length = 161/6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local440030644_0001_m_000161_0 is done. And is in the process of committing%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #663%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #663%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 0ms%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local440030644_0001_m_000161_0' done.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local440030644_0001_m_000161_0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local440030644_0001_m_000162_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.SortedRanges - currentIndex 0   0:0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - mapreduce.cluster.local.dir for child : /tmp/hadoop-gaoch/mapred/local/localRunner//root/jobcache/job_local440030644_0001/attempt_local440030644_0001_m_000162_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - using new api for output committer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7676b4d1%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9001/TestWordCountOutput/File_input-Test-CANA-483960newsML.txt-r-00000:0+296%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #664%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #664%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=296
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743239_2415; getBlockSize()=296; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743239_2415; getBlockSize()=296; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #665%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #665%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=296
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743239_2415; getBlockSize()=296; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743239_2415; getBlockSize()=296; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 127.0.0.1:50010%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - %INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 3960; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214280(104857120); length = 117/6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local440030644_0001_m_000162_0 is done. And is in the process of committing%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #666%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #666%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 0ms%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local440030644_0001_m_000162_0' done.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local440030644_0001_m_000162_0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local440030644_0001_m_000163_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.SortedRanges - currentIndex 0   0:0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - mapreduce.cluster.local.dir for child : /tmp/hadoop-gaoch/mapred/local/localRunner//root/jobcache/job_local440030644_0001/attempt_local440030644_0001_m_000163_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - using new api for output committer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1fbe6fa7%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9001/TestWordCountOutput/File_input-Test-CANA-486839newsML.txt-r-00000:0+290%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #667%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #667%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=290
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743270_2446; getBlockSize()=290; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743270_2446; getBlockSize()=290; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #668%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #668%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=290
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743270_2446; getBlockSize()=290; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743270_2446; getBlockSize()=290; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 127.0.0.1:50010%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - %INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 3960; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214280(104857120); length = 117/6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local440030644_0001_m_000163_0 is done. And is in the process of committing%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #669%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #669%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 0ms%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local440030644_0001_m_000163_0' done.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local440030644_0001_m_000163_0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local440030644_0001_m_000164_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.SortedRanges - currentIndex 0   0:0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - mapreduce.cluster.local.dir for child : /tmp/hadoop-gaoch/mapred/local/localRunner//root/jobcache/job_local440030644_0001/attempt_local440030644_0001_m_000164_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - using new api for output committer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@25e6b58f%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9001/TestWordCountOutput/File_input-Test-CANA-483959newsML.txt-r-00000:0+282%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #670%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #670%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=282
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743297_2473; getBlockSize()=282; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743297_2473; getBlockSize()=282; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #671%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #671%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=282
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743297_2473; getBlockSize()=282; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743297_2473; getBlockSize()=282; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 127.0.0.1:50010%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - %INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 4356; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214268(104857072); length = 129/6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local440030644_0001_m_000164_0 is done. And is in the process of committing%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #672%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #672%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 0ms%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local440030644_0001_m_000164_0' done.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local440030644_0001_m_000164_0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local440030644_0001_m_000165_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.SortedRanges - currentIndex 0   0:0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - mapreduce.cluster.local.dir for child : /tmp/hadoop-gaoch/mapred/local/localRunner//root/jobcache/job_local440030644_0001/attempt_local440030644_0001_m_000165_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - using new api for output committer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@526d894%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9001/TestWordCountOutput/File_input-Test-CANA-477897newsML.txt-r-00000:0+280%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #673%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #673%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=280
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743356_2532; getBlockSize()=280; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743356_2532; getBlockSize()=280; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #674%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #674%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 16ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=280
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743356_2532; getBlockSize()=280; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743356_2532; getBlockSize()=280; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 127.0.0.1:50010%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - %INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 4884; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214252(104857008); length = 145/6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local440030644_0001_m_000165_0 is done. And is in the process of committing%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #675%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #675%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 0ms%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local440030644_0001_m_000165_0' done.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local440030644_0001_m_000165_0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local440030644_0001_m_000166_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.SortedRanges - currentIndex 0   0:0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - mapreduce.cluster.local.dir for child : /tmp/hadoop-gaoch/mapred/local/localRunner//root/jobcache/job_local440030644_0001/attempt_local440030644_0001_m_000166_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - using new api for output committer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@495f111f%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9001/TestWordCountOutput/File_input-Test-CANA-477893newsML.txt-r-00000:0+274%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #676%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #676%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=274
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743291_2467; getBlockSize()=274; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743291_2467; getBlockSize()=274; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #677%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #677%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=274
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743291_2467; getBlockSize()=274; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743291_2467; getBlockSize()=274; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 127.0.0.1:50010%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - %INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 4752; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214256(104857024); length = 141/6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local440030644_0001_m_000166_0 is done. And is in the process of committing%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #678%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #678%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 0ms%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local440030644_0001_m_000166_0' done.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local440030644_0001_m_000166_0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local440030644_0001_m_000167_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.SortedRanges - currentIndex 0   0:0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - mapreduce.cluster.local.dir for child : /tmp/hadoop-gaoch/mapred/local/localRunner//root/jobcache/job_local440030644_0001/attempt_local440030644_0001_m_000167_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - using new api for output committer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3df58e2f%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9001/TestWordCountOutput/File_input-Test-AUSTR-486636newsML.txt-r-00000:0+241%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #679%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #679%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=241
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743373_2549; getBlockSize()=241; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743373_2549; getBlockSize()=241; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #680%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #680%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=241
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743373_2549; getBlockSize()=241; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743373_2549; getBlockSize()=241; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 127.0.0.1:50010%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - %INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 3857; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214284(104857136); length = 113/6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local440030644_0001_m_000167_0 is done. And is in the process of committing%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #681%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #681%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 0ms%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local440030644_0001_m_000167_0' done.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local440030644_0001_m_000167_0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local440030644_0001_m_000168_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.SortedRanges - currentIndex 0   0:0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - mapreduce.cluster.local.dir for child : /tmp/hadoop-gaoch/mapred/local/localRunner//root/jobcache/job_local440030644_0001/attempt_local440030644_0001_m_000168_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - using new api for output committer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@26d7066a%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9001/TestWordCountOutput/File_input-Test-CANA-481052newsML.txt-r-00000:0+138%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #682%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #682%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 15ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=138
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743338_2514; getBlockSize()=138; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743338_2514; getBlockSize()=138; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #683%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #683%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=138
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743338_2514; getBlockSize()=138; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743338_2514; getBlockSize()=138; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 127.0.0.1:50010%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - %INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1848; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214344(104857376); length = 53/6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local440030644_0001_m_000168_0 is done. And is in the process of committing%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #684%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #684%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 0ms%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local440030644_0001_m_000168_0' done.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local440030644_0001_m_000168_0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local440030644_0001_m_000169_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.SortedRanges - currentIndex 0   0:0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - mapreduce.cluster.local.dir for child : /tmp/hadoop-gaoch/mapred/local/localRunner//root/jobcache/job_local440030644_0001/attempt_local440030644_0001_m_000169_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - using new api for output committer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@20d5a8f%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9001/TestWordCountOutput/File_input-Test-CANA-478311newsML.txt-r-00000:0+129%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #685%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #685%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 15ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=129
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743275_2451; getBlockSize()=129; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743275_2451; getBlockSize()=129; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #686%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #686%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=129
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743275_2451; getBlockSize()=129; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743275_2451; getBlockSize()=129; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 127.0.0.1:50010%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - %INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1980; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214340(104857360); length = 57/6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local440030644_0001_m_000169_0 is done. And is in the process of committing%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #687%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #687%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 0ms%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local440030644_0001_m_000169_0' done.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local440030644_0001_m_000169_0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local440030644_0001_m_000170_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.SortedRanges - currentIndex 0   0:0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - mapreduce.cluster.local.dir for child : /tmp/hadoop-gaoch/mapred/local/localRunner//root/jobcache/job_local440030644_0001/attempt_local440030644_0001_m_000170_0%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - using new api for output committer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7402cde6%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9001/TestWordCountOutput/File_input-Test-AUSTR-480306newsML.txt-r-00000:0+104%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #688%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #688%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=104
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743388_2564; getBlockSize()=104; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743388_2564; getBlockSize()=104; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Trying map output collector class: org.apache.hadoop.mapred.MapTask$MapOutputBuffer%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #689%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #689%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=104
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743388_2564; getBlockSize()=104; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743388_2564; getBlockSize()=104; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 127.0.0.1:50010%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - %INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1596; bufvoid = 104857600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214352(104857408); length = 45/6553600%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local440030644_0001_m_000170_0 is done. And is in the process of committing%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #690%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #690%DEBUG LocalJobRunner Map Task Executor #0 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 0ms%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local440030644_0001_m_000170_0' done.%INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local440030644_0001_m_000170_0%INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.%DEBUG Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Starting reduce thread pool executor.%DEBUG Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Max local threads: 1%DEBUG Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Reduce tasks to process: 1%INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks%INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local440030644_0001_r_000000_0%DEBUG pool-6-thread-1 org.apache.hadoop.mapred.SortedRanges - currentIndex 0   0:0%DEBUG pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - mapreduce.cluster.local.dir for child : /tmp/hadoop-gaoch/mapred/local/localRunner//root/jobcache/job_local440030644_0001/attempt_local440030644_0001_r_000000_0%DEBUG pool-6-thread-1 org.apache.hadoop.mapred.Task - using new api for output committer%INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1%INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.%INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@235c613a%INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@50d42195%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=732168192, maxSingleShuffleLimit=183042048, mergeThreshold=483231040, ioSortFactor=10, memToMemMergeOutputsThreshold=10%INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local440030644_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events%DEBUG EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - Got 0 map completion events from 0%DEBUG EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - GetMapEventsThread about to sleep for 1000%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000090_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000090_0: Proceeding with shuffle since usedMemory (0) is lesser than memoryLimit (732168192).CommitMemory is (0)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000090_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000090_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->136%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000090_0 done 1 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000039_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000039_0: Proceeding with shuffle since usedMemory (136) is lesser than memoryLimit (732168192).CommitMemory is (136)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000039_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000039_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 2, commitMemory -> 136, usedMemory ->273%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000039_0 done 2 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000141_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000141_0: Proceeding with shuffle since usedMemory (273) is lesser than memoryLimit (732168192).CommitMemory is (273)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000141_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000141_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 3, commitMemory -> 273, usedMemory ->409%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000141_0 done 3 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000142_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000142_0: Proceeding with shuffle since usedMemory (409) is lesser than memoryLimit (732168192).CommitMemory is (409)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000142_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000142_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 4, commitMemory -> 409, usedMemory ->545%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000142_0 done 4 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000091_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000091_0: Proceeding with shuffle since usedMemory (545) is lesser than memoryLimit (732168192).CommitMemory is (545)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000091_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000091_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 5, commitMemory -> 545, usedMemory ->682%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000091_0 done 5 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000143_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000143_0: Proceeding with shuffle since usedMemory (682) is lesser than memoryLimit (732168192).CommitMemory is (682)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000143_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000143_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 6, commitMemory -> 682, usedMemory ->818%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000143_0 done 6 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000040_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000040_0: Proceeding with shuffle since usedMemory (818) is lesser than memoryLimit (732168192).CommitMemory is (818)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000040_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000040_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 7, commitMemory -> 818, usedMemory ->955%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000040_0 done 7 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000092_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000092_0: Proceeding with shuffle since usedMemory (955) is lesser than memoryLimit (732168192).CommitMemory is (955)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000092_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000092_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 8, commitMemory -> 955, usedMemory ->1091%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000092_0 done 8 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000041_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000041_0: Proceeding with shuffle since usedMemory (1091) is lesser than memoryLimit (732168192).CommitMemory is (1091)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000041_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000041_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 9, commitMemory -> 1091, usedMemory ->1228%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000041_0 done 9 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000138_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000138_0: Proceeding with shuffle since usedMemory (1228) is lesser than memoryLimit (732168192).CommitMemory is (1228)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000138_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000138_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 10, commitMemory -> 1228, usedMemory ->1365%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000138_0 done 10 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000087_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000087_0: Proceeding with shuffle since usedMemory (1365) is lesser than memoryLimit (732168192).CommitMemory is (1365)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000087_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000087_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 11, commitMemory -> 1365, usedMemory ->1502%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000087_0 done 11 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000139_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000139_0: Proceeding with shuffle since usedMemory (1502) is lesser than memoryLimit (732168192).CommitMemory is (1502)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000139_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000139_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 12, commitMemory -> 1502, usedMemory ->1639%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000139_0 done 12 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000036_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000036_0: Proceeding with shuffle since usedMemory (1639) is lesser than memoryLimit (732168192).CommitMemory is (1639)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000036_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000036_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 13, commitMemory -> 1639, usedMemory ->1776%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000036_0 done 13 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000088_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000088_0: Proceeding with shuffle since usedMemory (1776) is lesser than memoryLimit (732168192).CommitMemory is (1776)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000088_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000088_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 14, commitMemory -> 1776, usedMemory ->1913%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000088_0 done 14 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000037_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000037_0: Proceeding with shuffle since usedMemory (1913) is lesser than memoryLimit (732168192).CommitMemory is (1913)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000037_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000037_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 15, commitMemory -> 1913, usedMemory ->2050%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000037_0 done 15 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000038_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000038_0: Proceeding with shuffle since usedMemory (2050) is lesser than memoryLimit (732168192).CommitMemory is (2050)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000038_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000038_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 16, commitMemory -> 2050, usedMemory ->2186%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000038_0 done 16 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000140_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000140_0: Proceeding with shuffle since usedMemory (2186) is lesser than memoryLimit (732168192).CommitMemory is (2186)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000140_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000140_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 17, commitMemory -> 2186, usedMemory ->2323%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000140_0 done 17 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000089_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000089_0: Proceeding with shuffle since usedMemory (2323) is lesser than memoryLimit (732168192).CommitMemory is (2323)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000089_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000089_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 18, commitMemory -> 2323, usedMemory ->2459%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000089_0 done 18 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000096_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000096_0: Proceeding with shuffle since usedMemory (2459) is lesser than memoryLimit (732168192).CommitMemory is (2459)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000096_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000096_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 19, commitMemory -> 2459, usedMemory ->2596%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000096_0 done 19 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000045_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000045_0: Proceeding with shuffle since usedMemory (2596) is lesser than memoryLimit (732168192).CommitMemory is (2596)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000045_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000045_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 20, commitMemory -> 2596, usedMemory ->2733%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000045_0 done 20 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000046_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000046_0: Proceeding with shuffle since usedMemory (2733) is lesser than memoryLimit (732168192).CommitMemory is (2733)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000046_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000046_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 21, commitMemory -> 2733, usedMemory ->2869%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000046_0 done 21 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000148_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000148_0: Proceeding with shuffle since usedMemory (2869) is lesser than memoryLimit (732168192).CommitMemory is (2869)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000148_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000148_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 22, commitMemory -> 2869, usedMemory ->3006%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000148_0 done 22 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000097_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000097_0: Proceeding with shuffle since usedMemory (3006) is lesser than memoryLimit (732168192).CommitMemory is (3006)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000097_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000097_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 23, commitMemory -> 3006, usedMemory ->3143%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000097_0 done 23 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000098_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000098_0: Proceeding with shuffle since usedMemory (3143) is lesser than memoryLimit (732168192).CommitMemory is (3143)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000098_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000098_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 24, commitMemory -> 3143, usedMemory ->3279%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000098_0 done 24 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000047_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000047_0: Proceeding with shuffle since usedMemory (3279) is lesser than memoryLimit (732168192).CommitMemory is (3279)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000047_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000047_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 25, commitMemory -> 3279, usedMemory ->3416%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000047_0 done 25 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000149_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000149_0: Proceeding with shuffle since usedMemory (3416) is lesser than memoryLimit (732168192).CommitMemory is (3416)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000149_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000149_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 26, commitMemory -> 3416, usedMemory ->3552%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000149_0 done 26 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000150_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000150_0: Proceeding with shuffle since usedMemory (3552) is lesser than memoryLimit (732168192).CommitMemory is (3552)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000150_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000150_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 27, commitMemory -> 3552, usedMemory ->3689%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000150_0 done 27 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000099_0%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%DEBUG EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - Got 0 map completion events from 0%DEBUG EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - GetMapEventsThread about to sleep for 1000%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000099_0: Proceeding with shuffle since usedMemory (3689) is lesser than memoryLimit (732168192).CommitMemory is (3689)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000099_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000099_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 28, commitMemory -> 3689, usedMemory ->3826%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000099_0 done 28 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000042_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000042_0: Proceeding with shuffle since usedMemory (3826) is lesser than memoryLimit (732168192).CommitMemory is (3826)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000042_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000042_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 29, commitMemory -> 3826, usedMemory ->3963%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000042_0 done 29 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000144_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000144_0: Proceeding with shuffle since usedMemory (3963) is lesser than memoryLimit (732168192).CommitMemory is (3963)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000144_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000144_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 30, commitMemory -> 3963, usedMemory ->4099%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000144_0 done 30 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000093_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000093_0: Proceeding with shuffle since usedMemory (4099) is lesser than memoryLimit (732168192).CommitMemory is (4099)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000093_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000093_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 31, commitMemory -> 4099, usedMemory ->4235%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000093_0 done 31 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000094_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000094_0: Proceeding with shuffle since usedMemory (4235) is lesser than memoryLimit (732168192).CommitMemory is (4235)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000094_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000094_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 32, commitMemory -> 4235, usedMemory ->4371%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000094_0 done 32 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000043_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000043_0: Proceeding with shuffle since usedMemory (4371) is lesser than memoryLimit (732168192).CommitMemory is (4371)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000043_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000043_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 33, commitMemory -> 4371, usedMemory ->4507%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000043_0 done 33 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000145_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000145_0: Proceeding with shuffle since usedMemory (4507) is lesser than memoryLimit (732168192).CommitMemory is (4507)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000145_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000145_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 34, commitMemory -> 4507, usedMemory ->4644%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000145_0 done 34 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000146_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000146_0: Proceeding with shuffle since usedMemory (4644) is lesser than memoryLimit (732168192).CommitMemory is (4644)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000146_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000146_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 35, commitMemory -> 4644, usedMemory ->4781%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000146_0 done 35 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000095_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000095_0: Proceeding with shuffle since usedMemory (4781) is lesser than memoryLimit (732168192).CommitMemory is (4781)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000095_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000095_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 36, commitMemory -> 4781, usedMemory ->4918%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000095_0 done 36 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000147_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000147_0: Proceeding with shuffle since usedMemory (4918) is lesser than memoryLimit (732168192).CommitMemory is (4918)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000147_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000147_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 37, commitMemory -> 4918, usedMemory ->5054%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000147_0 done 37 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000044_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000044_0: Proceeding with shuffle since usedMemory (5054) is lesser than memoryLimit (732168192).CommitMemory is (5054)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000044_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000044_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 38, commitMemory -> 5054, usedMemory ->5190%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000044_0 done 38 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000154_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000154_0: Proceeding with shuffle since usedMemory (5190) is lesser than memoryLimit (732168192).CommitMemory is (5190)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000154_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000154_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 39, commitMemory -> 5190, usedMemory ->5326%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000154_0 done 39 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000103_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000103_0: Proceeding with shuffle since usedMemory (5326) is lesser than memoryLimit (732168192).CommitMemory is (5326)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000103_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000103_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 40, commitMemory -> 5326, usedMemory ->5463%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000103_0 done 40 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000000_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000000_0: Proceeding with shuffle since usedMemory (5463) is lesser than memoryLimit (732168192).CommitMemory is (5463)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000000_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000000_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 41, commitMemory -> 5463, usedMemory ->5600%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000000_0 done 41 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000155_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000155_0: Proceeding with shuffle since usedMemory (5600) is lesser than memoryLimit (732168192).CommitMemory is (5600)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000155_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000155_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 42, commitMemory -> 5600, usedMemory ->5737%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000155_0 done 42 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000052_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000052_0: Proceeding with shuffle since usedMemory (5737) is lesser than memoryLimit (732168192).CommitMemory is (5737)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000052_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000052_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 43, commitMemory -> 5737, usedMemory ->5873%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000052_0 done 43 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000001_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000001_0: Proceeding with shuffle since usedMemory (5873) is lesser than memoryLimit (732168192).CommitMemory is (5873)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000001_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000001_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 44, commitMemory -> 5873, usedMemory ->6010%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000001_0 done 44 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000002_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000002_0: Proceeding with shuffle since usedMemory (6010) is lesser than memoryLimit (732168192).CommitMemory is (6010)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000002_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000002_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 45, commitMemory -> 6010, usedMemory ->6147%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000002_0 done 45 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000104_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000104_0: Proceeding with shuffle since usedMemory (6147) is lesser than memoryLimit (732168192).CommitMemory is (6147)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000104_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000104_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 46, commitMemory -> 6147, usedMemory ->6284%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000104_0 done 46 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000053_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000053_0: Proceeding with shuffle since usedMemory (6284) is lesser than memoryLimit (732168192).CommitMemory is (6284)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000053_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000053_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 47, commitMemory -> 6284, usedMemory ->6421%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000053_0 done 47 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000054_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000054_0: Proceeding with shuffle since usedMemory (6421) is lesser than memoryLimit (732168192).CommitMemory is (6421)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000054_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000054_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 48, commitMemory -> 6421, usedMemory ->6558%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000054_0 done 48 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000003_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000003_0: Proceeding with shuffle since usedMemory (6558) is lesser than memoryLimit (732168192).CommitMemory is (6558)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000003_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000003_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 49, commitMemory -> 6558, usedMemory ->6695%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000003_0 done 49 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000156_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000156_0: Proceeding with shuffle since usedMemory (6695) is lesser than memoryLimit (732168192).CommitMemory is (6695)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000156_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000156_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 50, commitMemory -> 6695, usedMemory ->6831%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000156_0 done 50 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000105_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000105_0: Proceeding with shuffle since usedMemory (6831) is lesser than memoryLimit (732168192).CommitMemory is (6831)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000105_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000105_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 51, commitMemory -> 6831, usedMemory ->6967%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000105_0 done 51 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000151_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000151_0: Proceeding with shuffle since usedMemory (6967) is lesser than memoryLimit (732168192).CommitMemory is (6967)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000151_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000151_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 52, commitMemory -> 6967, usedMemory ->7103%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000151_0 done 52 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000048_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000048_0: Proceeding with shuffle since usedMemory (7103) is lesser than memoryLimit (732168192).CommitMemory is (7103)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000048_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000048_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 53, commitMemory -> 7103, usedMemory ->7240%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000048_0 done 53 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000100_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000100_0: Proceeding with shuffle since usedMemory (7240) is lesser than memoryLimit (732168192).CommitMemory is (7240)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000100_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000100_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 54, commitMemory -> 7240, usedMemory ->7377%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000100_0 done 54 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000049_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000049_0: Proceeding with shuffle since usedMemory (7377) is lesser than memoryLimit (732168192).CommitMemory is (7377)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000049_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000049_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 55, commitMemory -> 7377, usedMemory ->7514%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000049_0 done 55 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000050_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000050_0: Proceeding with shuffle since usedMemory (7514) is lesser than memoryLimit (732168192).CommitMemory is (7514)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000050_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000050_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 56, commitMemory -> 7514, usedMemory ->7651%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000050_0 done 56 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000152_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000152_0: Proceeding with shuffle since usedMemory (7651) is lesser than memoryLimit (732168192).CommitMemory is (7651)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000152_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000152_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 57, commitMemory -> 7651, usedMemory ->7787%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000152_0 done 57 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000101_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000101_0: Proceeding with shuffle since usedMemory (7787) is lesser than memoryLimit (732168192).CommitMemory is (7787)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000101_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000101_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 58, commitMemory -> 7787, usedMemory ->7924%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000101_0 done 58 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000102_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000102_0: Proceeding with shuffle since usedMemory (7924) is lesser than memoryLimit (732168192).CommitMemory is (7924)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000102_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000102_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 59, commitMemory -> 7924, usedMemory ->8061%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000102_0 done 59 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000051_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000051_0: Proceeding with shuffle since usedMemory (8061) is lesser than memoryLimit (732168192).CommitMemory is (8061)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000051_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000051_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 60, commitMemory -> 8061, usedMemory ->8197%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000051_0 done 60 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000153_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000153_0: Proceeding with shuffle since usedMemory (8197) is lesser than memoryLimit (732168192).CommitMemory is (8197)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000153_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000153_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 61, commitMemory -> 8197, usedMemory ->8333%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000153_0 done 61 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000058_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000058_0: Proceeding with shuffle since usedMemory (8333) is lesser than memoryLimit (732168192).CommitMemory is (8333)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000058_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000058_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 62, commitMemory -> 8333, usedMemory ->8470%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000058_0 done 62 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000007_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000007_0: Proceeding with shuffle since usedMemory (8470) is lesser than memoryLimit (732168192).CommitMemory is (8470)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000007_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000007_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 63, commitMemory -> 8470, usedMemory ->8607%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000007_0 done 63 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000160_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000160_0: Proceeding with shuffle since usedMemory (8607) is lesser than memoryLimit (732168192).CommitMemory is (8607)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000160_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000160_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 64, commitMemory -> 8607, usedMemory ->8743%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000160_0 done 64 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000109_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000109_0: Proceeding with shuffle since usedMemory (8743) is lesser than memoryLimit (732168192).CommitMemory is (8743)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000109_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000109_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 65, commitMemory -> 8743, usedMemory ->8879%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000109_0 done 65 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000110_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000110_0: Proceeding with shuffle since usedMemory (8879) is lesser than memoryLimit (732168192).CommitMemory is (8879)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000110_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000110_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 66, commitMemory -> 8879, usedMemory ->9015%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000110_0 done 66 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000059_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000059_0: Proceeding with shuffle since usedMemory (9015) is lesser than memoryLimit (732168192).CommitMemory is (9015)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000059_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000059_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 67, commitMemory -> 9015, usedMemory ->9151%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000059_0 done 67 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000161_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000161_0: Proceeding with shuffle since usedMemory (9151) is lesser than memoryLimit (732168192).CommitMemory is (9151)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000161_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000161_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 68, commitMemory -> 9151, usedMemory ->9288%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000161_0 done 68 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000162_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000162_0: Proceeding with shuffle since usedMemory (9288) is lesser than memoryLimit (732168192).CommitMemory is (9288)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000162_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000162_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 69, commitMemory -> 9288, usedMemory ->9424%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000162_0 done 69 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000111_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000111_0: Proceeding with shuffle since usedMemory (9424) is lesser than memoryLimit (732168192).CommitMemory is (9424)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000111_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000111_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 70, commitMemory -> 9424, usedMemory ->9560%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000111_0 done 70 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000008_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000008_0: Proceeding with shuffle since usedMemory (9560) is lesser than memoryLimit (732168192).CommitMemory is (9560)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000008_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000008_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 71, commitMemory -> 9560, usedMemory ->9697%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000008_0 done 71 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000163_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000163_0: Proceeding with shuffle since usedMemory (9697) is lesser than memoryLimit (732168192).CommitMemory is (9697)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000163_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000163_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 72, commitMemory -> 9697, usedMemory ->9833%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000163_0 done 72 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000060_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000060_0: Proceeding with shuffle since usedMemory (9833) is lesser than memoryLimit (732168192).CommitMemory is (9833)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000060_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000060_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 73, commitMemory -> 9833, usedMemory ->9969%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000060_0 done 73 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000009_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000009_0: Proceeding with shuffle since usedMemory (9969) is lesser than memoryLimit (732168192).CommitMemory is (9969)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000009_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000009_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 74, commitMemory -> 9969, usedMemory ->10106%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000009_0 done 74 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000106_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000106_0: Proceeding with shuffle since usedMemory (10106) is lesser than memoryLimit (732168192).CommitMemory is (10106)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000106_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000106_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 75, commitMemory -> 10106, usedMemory ->10242%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000106_0 done 75 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000055_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000055_0: Proceeding with shuffle since usedMemory (10242) is lesser than memoryLimit (732168192).CommitMemory is (10242)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000055_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000055_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 76, commitMemory -> 10242, usedMemory ->10378%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000055_0 done 76 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000157_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000157_0: Proceeding with shuffle since usedMemory (10378) is lesser than memoryLimit (732168192).CommitMemory is (10378)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000157_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000157_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 77, commitMemory -> 10378, usedMemory ->10514%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000157_0 done 77 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000158_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000158_0: Proceeding with shuffle since usedMemory (10514) is lesser than memoryLimit (732168192).CommitMemory is (10514)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000158_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000158_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 78, commitMemory -> 10514, usedMemory ->10651%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000158_0 done 78 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000107_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000107_0: Proceeding with shuffle since usedMemory (10651) is lesser than memoryLimit (732168192).CommitMemory is (10651)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000107_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000107_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 79, commitMemory -> 10651, usedMemory ->10788%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000107_0 done 79 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000004_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000004_0: Proceeding with shuffle since usedMemory (10788) is lesser than memoryLimit (732168192).CommitMemory is (10788)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000004_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000004_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 80, commitMemory -> 10788, usedMemory ->10925%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000004_0 done 80 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000159_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000159_0: Proceeding with shuffle since usedMemory (10925) is lesser than memoryLimit (732168192).CommitMemory is (10925)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000159_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000159_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 81, commitMemory -> 10925, usedMemory ->11062%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000159_0 done 81 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000056_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000056_0: Proceeding with shuffle since usedMemory (11062) is lesser than memoryLimit (732168192).CommitMemory is (11062)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000056_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000056_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 82, commitMemory -> 11062, usedMemory ->11199%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000056_0 done 82 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000005_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000005_0: Proceeding with shuffle since usedMemory (11199) is lesser than memoryLimit (732168192).CommitMemory is (11199)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000005_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000005_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 83, commitMemory -> 11199, usedMemory ->11336%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000005_0 done 83 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000006_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000006_0: Proceeding with shuffle since usedMemory (11336) is lesser than memoryLimit (732168192).CommitMemory is (11336)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000006_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000006_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 84, commitMemory -> 11336, usedMemory ->11473%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000006_0 done 84 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000108_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000108_0: Proceeding with shuffle since usedMemory (11473) is lesser than memoryLimit (732168192).CommitMemory is (11473)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000108_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000108_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 85, commitMemory -> 11473, usedMemory ->11610%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000108_0 done 85 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000057_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000057_0: Proceeding with shuffle since usedMemory (11610) is lesser than memoryLimit (732168192).CommitMemory is (11610)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000057_0 decomp: 136 len: 140 to MEMORY%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000057_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 86, commitMemory -> 11610, usedMemory ->11746%DEBUG EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - Got 0 map completion events from 0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000057_0 done 86 / 171 copied.%DEBUG EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - GetMapEventsThread about to sleep for 1000%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000167_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000167_0: Proceeding with shuffle since usedMemory (11746) is lesser than memoryLimit (732168192).CommitMemory is (11746)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000167_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000167_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 87, commitMemory -> 11746, usedMemory ->11883%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000167_0 done 87 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000064_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000064_0: Proceeding with shuffle since usedMemory (11883) is lesser than memoryLimit (732168192).CommitMemory is (11883)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000064_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000064_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 88, commitMemory -> 11883, usedMemory ->12019%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000064_0 done 88 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000013_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000013_0: Proceeding with shuffle since usedMemory (12019) is lesser than memoryLimit (732168192).CommitMemory is (12019)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000013_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000013_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 89, commitMemory -> 12019, usedMemory ->12155%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000013_0 done 89 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000014_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000014_0: Proceeding with shuffle since usedMemory (12155) is lesser than memoryLimit (732168192).CommitMemory is (12155)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000014_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000014_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 90, commitMemory -> 12155, usedMemory ->12291%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000014_0 done 90 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000116_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000116_0: Proceeding with shuffle since usedMemory (12291) is lesser than memoryLimit (732168192).CommitMemory is (12291)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000116_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000116_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 91, commitMemory -> 12291, usedMemory ->12428%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000116_0 done 91 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000065_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000065_0: Proceeding with shuffle since usedMemory (12428) is lesser than memoryLimit (732168192).CommitMemory is (12428)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000065_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000065_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 92, commitMemory -> 12428, usedMemory ->12564%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000065_0 done 92 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000066_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000066_0: Proceeding with shuffle since usedMemory (12564) is lesser than memoryLimit (732168192).CommitMemory is (12564)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000066_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000066_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 93, commitMemory -> 12564, usedMemory ->12700%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000066_0 done 93 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000015_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000015_0: Proceeding with shuffle since usedMemory (12700) is lesser than memoryLimit (732168192).CommitMemory is (12700)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000015_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000015_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 94, commitMemory -> 12700, usedMemory ->12837%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000015_0 done 94 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000168_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000168_0: Proceeding with shuffle since usedMemory (12837) is lesser than memoryLimit (732168192).CommitMemory is (12837)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000168_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000168_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 95, commitMemory -> 12837, usedMemory ->12973%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000168_0 done 95 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000117_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000117_0: Proceeding with shuffle since usedMemory (12973) is lesser than memoryLimit (732168192).CommitMemory is (12973)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000117_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000117_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 96, commitMemory -> 12973, usedMemory ->13109%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000117_0 done 96 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000118_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000118_0: Proceeding with shuffle since usedMemory (13109) is lesser than memoryLimit (732168192).CommitMemory is (13109)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000118_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000118_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 97, commitMemory -> 13109, usedMemory ->13245%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000118_0 done 97 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000067_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000067_0: Proceeding with shuffle since usedMemory (13245) is lesser than memoryLimit (732168192).CommitMemory is (13245)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000067_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000067_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 98, commitMemory -> 13245, usedMemory ->13381%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000067_0 done 98 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000169_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000169_0: Proceeding with shuffle since usedMemory (13381) is lesser than memoryLimit (732168192).CommitMemory is (13381)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000169_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000169_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 99, commitMemory -> 13381, usedMemory ->13517%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000169_0 done 99 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000010_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000010_0: Proceeding with shuffle since usedMemory (13517) is lesser than memoryLimit (732168192).CommitMemory is (13517)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000010_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000010_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 100, commitMemory -> 13517, usedMemory ->13653%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000010_0 done 100 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000112_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000112_0: Proceeding with shuffle since usedMemory (13653) is lesser than memoryLimit (732168192).CommitMemory is (13653)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000112_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000112_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 101, commitMemory -> 13653, usedMemory ->13790%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000112_0 done 101 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000061_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000061_0: Proceeding with shuffle since usedMemory (13790) is lesser than memoryLimit (732168192).CommitMemory is (13790)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000061_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000061_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 102, commitMemory -> 13790, usedMemory ->13926%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000061_0 done 102 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000062_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000062_0: Proceeding with shuffle since usedMemory (13926) is lesser than memoryLimit (732168192).CommitMemory is (13926)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000062_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000062_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 103, commitMemory -> 13926, usedMemory ->14062%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000062_0 done 103 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000011_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000011_0: Proceeding with shuffle since usedMemory (14062) is lesser than memoryLimit (732168192).CommitMemory is (14062)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000011_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000011_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 104, commitMemory -> 14062, usedMemory ->14198%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000011_0 done 104 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000164_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000164_0: Proceeding with shuffle since usedMemory (14198) is lesser than memoryLimit (732168192).CommitMemory is (14198)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000164_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000164_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 105, commitMemory -> 14198, usedMemory ->14334%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000164_0 done 105 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000113_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000113_0: Proceeding with shuffle since usedMemory (14334) is lesser than memoryLimit (732168192).CommitMemory is (14334)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000113_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000113_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 106, commitMemory -> 14334, usedMemory ->14471%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000113_0 done 106 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000114_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000114_0: Proceeding with shuffle since usedMemory (14471) is lesser than memoryLimit (732168192).CommitMemory is (14471)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000114_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000114_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 107, commitMemory -> 14471, usedMemory ->14608%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000114_0 done 107 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000063_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000063_0: Proceeding with shuffle since usedMemory (14608) is lesser than memoryLimit (732168192).CommitMemory is (14608)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000063_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000063_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 108, commitMemory -> 14608, usedMemory ->14745%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000063_0 done 108 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000165_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000165_0: Proceeding with shuffle since usedMemory (14745) is lesser than memoryLimit (732168192).CommitMemory is (14745)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000165_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000165_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 109, commitMemory -> 14745, usedMemory ->14881%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000165_0 done 109 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000166_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000166_0: Proceeding with shuffle since usedMemory (14881) is lesser than memoryLimit (732168192).CommitMemory is (14881)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000166_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000166_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 110, commitMemory -> 14881, usedMemory ->15017%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000166_0 done 110 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000115_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000115_0: Proceeding with shuffle since usedMemory (15017) is lesser than memoryLimit (732168192).CommitMemory is (15017)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000115_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000115_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 111, commitMemory -> 15017, usedMemory ->15154%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000115_0 done 111 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000012_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000012_0: Proceeding with shuffle since usedMemory (15154) is lesser than memoryLimit (732168192).CommitMemory is (15154)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000012_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000012_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 112, commitMemory -> 15154, usedMemory ->15291%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000012_0 done 112 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000122_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000122_0: Proceeding with shuffle since usedMemory (15291) is lesser than memoryLimit (732168192).CommitMemory is (15291)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000122_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000122_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 113, commitMemory -> 15291, usedMemory ->15428%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000122_0 done 113 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000071_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000071_0: Proceeding with shuffle since usedMemory (15428) is lesser than memoryLimit (732168192).CommitMemory is (15428)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000071_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000071_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 114, commitMemory -> 15428, usedMemory ->15564%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000071_0 done 114 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000123_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000123_0: Proceeding with shuffle since usedMemory (15564) is lesser than memoryLimit (732168192).CommitMemory is (15564)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000123_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000123_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 115, commitMemory -> 15564, usedMemory ->15701%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000123_0 done 115 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000020_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000020_0: Proceeding with shuffle since usedMemory (15701) is lesser than memoryLimit (732168192).CommitMemory is (15701)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000020_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000020_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 116, commitMemory -> 15701, usedMemory ->15837%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000020_0 done 116 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000072_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000072_0: Proceeding with shuffle since usedMemory (15837) is lesser than memoryLimit (732168192).CommitMemory is (15837)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000072_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000072_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 117, commitMemory -> 15837, usedMemory ->15973%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000072_0 done 117 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000021_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000021_0: Proceeding with shuffle since usedMemory (15973) is lesser than memoryLimit (732168192).CommitMemory is (15973)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000021_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000021_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 118, commitMemory -> 15973, usedMemory ->16110%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000021_0 done 118 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000022_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000022_0: Proceeding with shuffle since usedMemory (16110) is lesser than memoryLimit (732168192).CommitMemory is (16110)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000022_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000022_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 119, commitMemory -> 16110, usedMemory ->16246%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000022_0 done 119 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000124_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000124_0: Proceeding with shuffle since usedMemory (16246) is lesser than memoryLimit (732168192).CommitMemory is (16246)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000124_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000124_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 120, commitMemory -> 16246, usedMemory ->16383%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000124_0 done 120 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000073_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000073_0: Proceeding with shuffle since usedMemory (16383) is lesser than memoryLimit (732168192).CommitMemory is (16383)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000073_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000073_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 121, commitMemory -> 16383, usedMemory ->16520%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000073_0 done 121 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000170_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000170_0: Proceeding with shuffle since usedMemory (16520) is lesser than memoryLimit (732168192).CommitMemory is (16520)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000170_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000170_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 122, commitMemory -> 16520, usedMemory ->16657%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000170_0 done 122 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000119_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000119_0: Proceeding with shuffle since usedMemory (16657) is lesser than memoryLimit (732168192).CommitMemory is (16657)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000119_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000119_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 123, commitMemory -> 16657, usedMemory ->16794%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000119_0 done 123 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000016_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000016_0: Proceeding with shuffle since usedMemory (16794) is lesser than memoryLimit (732168192).CommitMemory is (16794)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000016_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000016_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 124, commitMemory -> 16794, usedMemory ->16931%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000016_0 done 124 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000068_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000068_0: Proceeding with shuffle since usedMemory (16931) is lesser than memoryLimit (732168192).CommitMemory is (16931)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000068_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000068_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 125, commitMemory -> 16931, usedMemory ->17067%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000068_0 done 125 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000017_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000017_0: Proceeding with shuffle since usedMemory (17067) is lesser than memoryLimit (732168192).CommitMemory is (17067)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000017_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000017_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 126, commitMemory -> 17067, usedMemory ->17204%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000017_0 done 126 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000018_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000018_0: Proceeding with shuffle since usedMemory (17204) is lesser than memoryLimit (732168192).CommitMemory is (17204)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000018_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000018_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 127, commitMemory -> 17204, usedMemory ->17340%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000018_0 done 127 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000120_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000120_0: Proceeding with shuffle since usedMemory (17340) is lesser than memoryLimit (732168192).CommitMemory is (17340)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000120_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000120_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 128, commitMemory -> 17340, usedMemory ->17476%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000120_0 done 128 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000069_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000069_0: Proceeding with shuffle since usedMemory (17476) is lesser than memoryLimit (732168192).CommitMemory is (17476)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000069_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000069_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 129, commitMemory -> 17476, usedMemory ->17613%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000069_0 done 129 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000070_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000070_0: Proceeding with shuffle since usedMemory (17613) is lesser than memoryLimit (732168192).CommitMemory is (17613)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000070_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000070_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 130, commitMemory -> 17613, usedMemory ->17750%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000070_0 done 130 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000019_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000019_0: Proceeding with shuffle since usedMemory (17750) is lesser than memoryLimit (732168192).CommitMemory is (17750)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000019_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000019_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 131, commitMemory -> 17750, usedMemory ->17886%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000019_0 done 131 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000121_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000121_0: Proceeding with shuffle since usedMemory (17886) is lesser than memoryLimit (732168192).CommitMemory is (17886)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000121_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000121_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 132, commitMemory -> 17886, usedMemory ->18022%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000121_0 done 132 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000026_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000026_0: Proceeding with shuffle since usedMemory (18022) is lesser than memoryLimit (732168192).CommitMemory is (18022)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000026_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000026_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 133, commitMemory -> 18022, usedMemory ->18159%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000026_0 done 133 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000128_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000128_0: Proceeding with shuffle since usedMemory (18159) is lesser than memoryLimit (732168192).CommitMemory is (18159)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000128_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000128_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 134, commitMemory -> 18159, usedMemory ->18295%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000128_0 done 134 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000077_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000077_0: Proceeding with shuffle since usedMemory (18295) is lesser than memoryLimit (732168192).CommitMemory is (18295)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000077_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000077_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 135, commitMemory -> 18295, usedMemory ->18431%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000077_0 done 135 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000078_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000078_0: Proceeding with shuffle since usedMemory (18431) is lesser than memoryLimit (732168192).CommitMemory is (18431)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000078_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000078_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 136, commitMemory -> 18431, usedMemory ->18567%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000078_0 done 136 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000027_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000027_0: Proceeding with shuffle since usedMemory (18567) is lesser than memoryLimit (732168192).CommitMemory is (18567)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000027_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000027_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 137, commitMemory -> 18567, usedMemory ->18704%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000027_0 done 137 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000129_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000129_0: Proceeding with shuffle since usedMemory (18704) is lesser than memoryLimit (732168192).CommitMemory is (18704)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000129_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000129_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 138, commitMemory -> 18704, usedMemory ->18840%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000129_0 done 138 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000130_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000130_0: Proceeding with shuffle since usedMemory (18840) is lesser than memoryLimit (732168192).CommitMemory is (18840)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000130_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000130_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 139, commitMemory -> 18840, usedMemory ->18976%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000130_0 done 139 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000079_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000079_0: Proceeding with shuffle since usedMemory (18976) is lesser than memoryLimit (732168192).CommitMemory is (18976)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000079_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000079_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 140, commitMemory -> 18976, usedMemory ->19112%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000079_0 done 140 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000131_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000131_0: Proceeding with shuffle since usedMemory (19112) is lesser than memoryLimit (732168192).CommitMemory is (19112)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000131_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000131_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 141, commitMemory -> 19112, usedMemory ->19249%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000131_0 done 141 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000028_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000028_0: Proceeding with shuffle since usedMemory (19249) is lesser than memoryLimit (732168192).CommitMemory is (19249)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000028_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000028_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 142, commitMemory -> 19249, usedMemory ->19386%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000028_0 done 142 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000074_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000074_0: Proceeding with shuffle since usedMemory (19386) is lesser than memoryLimit (732168192).CommitMemory is (19386)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000074_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000074_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 143, commitMemory -> 19386, usedMemory ->19523%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000074_0 done 143 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000023_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000023_0: Proceeding with shuffle since usedMemory (19523) is lesser than memoryLimit (732168192).CommitMemory is (19523)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000023_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000023_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 144, commitMemory -> 19523, usedMemory ->19659%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000023_0 done 144 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000125_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000125_0: Proceeding with shuffle since usedMemory (19659) is lesser than memoryLimit (732168192).CommitMemory is (19659)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000125_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000125_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 145, commitMemory -> 19659, usedMemory ->19796%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000125_0 done 145 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000126_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000126_0: Proceeding with shuffle since usedMemory (19796) is lesser than memoryLimit (732168192).CommitMemory is (19796)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000126_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000126_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 146, commitMemory -> 19796, usedMemory ->19933%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000126_0 done 146 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000075_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000075_0: Proceeding with shuffle since usedMemory (19933) is lesser than memoryLimit (732168192).CommitMemory is (19933)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000075_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000075_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 147, commitMemory -> 19933, usedMemory ->20070%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000075_0 done 147 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000127_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000127_0: Proceeding with shuffle since usedMemory (20070) is lesser than memoryLimit (732168192).CommitMemory is (20070)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000127_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000127_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 148, commitMemory -> 20070, usedMemory ->20206%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000127_0 done 148 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000024_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000024_0: Proceeding with shuffle since usedMemory (20206) is lesser than memoryLimit (732168192).CommitMemory is (20206)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000024_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000024_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 149, commitMemory -> 20206, usedMemory ->20342%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000024_0 done 149 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000076_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000076_0: Proceeding with shuffle since usedMemory (20342) is lesser than memoryLimit (732168192).CommitMemory is (20342)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000076_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000076_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 150, commitMemory -> 20342, usedMemory ->20478%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000076_0 done 150 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000025_0%DEBUG EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - Got 0 map completion events from 0%DEBUG EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - GetMapEventsThread about to sleep for 1000%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000025_0: Proceeding with shuffle since usedMemory (20478) is lesser than memoryLimit (732168192).CommitMemory is (20478)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000025_0 decomp: 137 len: 141 to MEMORY%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000025_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 151, commitMemory -> 20478, usedMemory ->20615%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000025_0 done 151 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000135_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000135_0: Proceeding with shuffle since usedMemory (20615) is lesser than memoryLimit (732168192).CommitMemory is (20615)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000135_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000135_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 152, commitMemory -> 20615, usedMemory ->20751%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000135_0 done 152 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000032_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000032_0: Proceeding with shuffle since usedMemory (20751) is lesser than memoryLimit (732168192).CommitMemory is (20751)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000032_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000032_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 153, commitMemory -> 20751, usedMemory ->20888%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000032_0 done 153 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000084_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000084_0: Proceeding with shuffle since usedMemory (20888) is lesser than memoryLimit (732168192).CommitMemory is (20888)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000084_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000084_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 154, commitMemory -> 20888, usedMemory ->21025%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000084_0 done 154 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000033_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000033_0: Proceeding with shuffle since usedMemory (21025) is lesser than memoryLimit (732168192).CommitMemory is (21025)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000033_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000033_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 155, commitMemory -> 21025, usedMemory ->21162%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000033_0 done 155 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000034_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000034_0: Proceeding with shuffle since usedMemory (21162) is lesser than memoryLimit (732168192).CommitMemory is (21162)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000034_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000034_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 156, commitMemory -> 21162, usedMemory ->21299%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000034_0 done 156 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000136_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000136_0: Proceeding with shuffle since usedMemory (21299) is lesser than memoryLimit (732168192).CommitMemory is (21299)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000136_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000136_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 157, commitMemory -> 21299, usedMemory ->21436%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000136_0 done 157 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000085_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000085_0: Proceeding with shuffle since usedMemory (21436) is lesser than memoryLimit (732168192).CommitMemory is (21436)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000085_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000085_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 158, commitMemory -> 21436, usedMemory ->21572%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000085_0 done 158 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000086_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000086_0: Proceeding with shuffle since usedMemory (21572) is lesser than memoryLimit (732168192).CommitMemory is (21572)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000086_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000086_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 159, commitMemory -> 21572, usedMemory ->21709%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000086_0 done 159 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000035_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000035_0: Proceeding with shuffle since usedMemory (21709) is lesser than memoryLimit (732168192).CommitMemory is (21709)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000035_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000035_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 160, commitMemory -> 21709, usedMemory ->21846%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000035_0 done 160 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000137_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000137_0: Proceeding with shuffle since usedMemory (21846) is lesser than memoryLimit (732168192).CommitMemory is (21846)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000137_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000137_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 161, commitMemory -> 21846, usedMemory ->21982%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000137_0 done 161 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000080_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000080_0: Proceeding with shuffle since usedMemory (21982) is lesser than memoryLimit (732168192).CommitMemory is (21982)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000080_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000080_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 162, commitMemory -> 21982, usedMemory ->22118%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000080_0 done 162 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000029_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000029_0: Proceeding with shuffle since usedMemory (22118) is lesser than memoryLimit (732168192).CommitMemory is (22118)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000029_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000029_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 163, commitMemory -> 22118, usedMemory ->22255%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000029_0 done 163 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000030_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000030_0: Proceeding with shuffle since usedMemory (22255) is lesser than memoryLimit (732168192).CommitMemory is (22255)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000030_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000030_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 164, commitMemory -> 22255, usedMemory ->22392%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000030_0 done 164 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000132_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000132_0: Proceeding with shuffle since usedMemory (22392) is lesser than memoryLimit (732168192).CommitMemory is (22392)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000132_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000132_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 165, commitMemory -> 22392, usedMemory ->22528%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000132_0 done 165 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000081_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000081_0: Proceeding with shuffle since usedMemory (22528) is lesser than memoryLimit (732168192).CommitMemory is (22528)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000081_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000081_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 166, commitMemory -> 22528, usedMemory ->22665%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000081_0 done 166 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000082_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000082_0: Proceeding with shuffle since usedMemory (22665) is lesser than memoryLimit (732168192).CommitMemory is (22665)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000082_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000082_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 167, commitMemory -> 22665, usedMemory ->22802%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000082_0 done 167 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000031_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000031_0: Proceeding with shuffle since usedMemory (22802) is lesser than memoryLimit (732168192).CommitMemory is (22802)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000031_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000031_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 168, commitMemory -> 22802, usedMemory ->22939%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000031_0 done 168 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000133_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000133_0: Proceeding with shuffle since usedMemory (22939) is lesser than memoryLimit (732168192).CommitMemory is (22939)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000133_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000133_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 169, commitMemory -> 22939, usedMemory ->23075%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000133_0 done 169 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000134_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000134_0: Proceeding with shuffle since usedMemory (23075) is lesser than memoryLimit (732168192).CommitMemory is (23075)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000134_0 decomp: 136 len: 140 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 136 bytes from map-output for attempt_local440030644_0001_m_000134_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 136, inMemoryMapOutputs.size() -> 170, commitMemory -> 23075, usedMemory ->23211%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000134_0 done 170 / 171 copied.%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - LocalFetcher 1 going to fetch: attempt_local440030644_0001_m_000083_0%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - attempt_local440030644_0001_m_000083_0: Proceeding with shuffle since usedMemory (23211) is lesser than memoryLimit (732168192).CommitMemory is (23211)%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local440030644_0001_m_000083_0 decomp: 137 len: 141 to MEMORY%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 137 bytes from map-output for attempt_local440030644_0001_m_000083_0%INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 137, inMemoryMapOutputs.size() -> 171, commitMemory -> 23211, usedMemory ->23348%DEBUG localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl - map attempt_local440030644_0001_m_000083_0 done 171 / 171 copied.%INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning%INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 171 / 171 copied.%INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 171 in-memory map-outputs and 0 on-disk map-outputs%INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 171 sorted segments%INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 171 segments left of total size: 15048 bytes%INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 171 segments, 23348 bytes to disk to satisfy reduce memory limit%DEBUG pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Disk file: /tmp/hadoop-gaoch/mapred/local/localRunner/root/jobcache/job_local440030644_0001/attempt_local440030644_0001_r_000000_0/output/map_90.out.merged Length is 23012%INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 23012 bytes from disk%INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce%INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments%INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 22959 bytes%INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 171 / 171 copied.%DEBUG pool-6-thread-1 org.apache.hadoop.hdfs.DFSClient - /TestResultOutput/_temporary/0/_temporary/attempt_local440030644_0001_r_000000_0/part-r-00000: masked=rw-r--r--%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #691%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #691%DEBUG pool-6-thread-1 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: create took 219ms%DEBUG pool-6-thread-1 org.apache.hadoop.hdfs.DFSClient - computePacketChunkSize: src=/TestResultOutput/_temporary/0/_temporary/attempt_local440030644_0001_r_000000_0/part-r-00000, chunkSize=516, chunksPerPacket=126, packetSize=65016%INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords%DEBUG LeaseRenewer:root@localhost:9001 org.apache.hadoop.hdfs.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1696764538_1] with renew id 1 started%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #692%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #692%DEBUG pool-6-thread-1 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getListing took 0ms%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #693%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #693%DEBUG pool-6-thread-1 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG pool-6-thread-1 org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=31
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743042_2218; getBlockSize()=31; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743042_2218; getBlockSize()=31; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG pool-6-thread-1 org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 127.0.0.1:50010%DEBUG pool-6-thread-1 org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient - SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]%INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1%DEBUG pool-6-thread-1 org.apache.hadoop.hdfs.DFSClient - /TestResultOutput/_temporary/0/_temporary/attempt_local440030644_0001_r_000000_0/Class_AUSTR-r-00000: masked=rw-r--r--%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #694%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #694%DEBUG pool-6-thread-1 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: create took 62ms%DEBUG pool-6-thread-1 org.apache.hadoop.hdfs.DFSClient - computePacketChunkSize: src=/TestResultOutput/_temporary/0/_temporary/attempt_local440030644_0001_r_000000_0/Class_AUSTR-r-00000, chunkSize=516, chunksPerPacket=126, packetSize=65016%INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1%DEBUG pool-6-thread-1 org.apache.hadoop.hdfs.DFSClient - /TestResultOutput/_temporary/0/_temporary/attempt_local440030644_0001_r_000000_0/Class_CANA-r-00000: masked=rw-r--r--%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #695%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #695%DEBUG pool-6-thread-1 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: create took 47ms%DEBUG pool-6-thread-1 org.apache.hadoop.hdfs.DFSClient - computePacketChunkSize: src=/TestResultOutput/_temporary/0/_temporary/attempt_local440030644_0001_r_000000_0/Class_CANA-r-00000, chunkSize=516, chunksPerPacket=126, packetSize=65016%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%DEBUG pool-6-thread-1 org.apache.hadoop.hdfs.DFSClient - DFSClient writeChunk allocating new packet seqno=0, src=/TestResultOutput/_temporary/0/_temporary/attempt_local440030644_0001_r_000000_0/Class_CANA-r-00000, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0%DEBUG pool-6-thread-1 org.apache.hadoop.hdfs.DFSClient - Queued packet 0%DEBUG pool-6-thread-1 org.apache.hadoop.hdfs.DFSClient - Queued packet 1%DEBUG pool-6-thread-1 org.apache.hadoop.hdfs.DFSClient - Waiting for ack for: 1%DEBUG Thread-357 org.apache.hadoop.hdfs.DFSClient - Allocating new block%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #696%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #696%DEBUG Thread-357 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: addBlock took 172ms%DEBUG Thread-357 org.apache.hadoop.hdfs.DFSClient - pipeline = DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]%DEBUG Thread-357 org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 127.0.0.1:50010%DEBUG Thread-357 org.apache.hadoop.hdfs.DFSClient - Send buf size 131072%DEBUG Thread-357 org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient - SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]%INFO communication thread org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce%INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%DEBUG DataStreamer for file /TestResultOutput/_temporary/0/_temporary/attempt_local440030644_0001_r_000000_0/Class_CANA-r-00000 block BP-593636016-192.168.157.1-1541301219238:blk_1073743402_2578 org.apache.hadoop.hdfs.DFSClient - DataStreamer block BP-593636016-192.168.157.1-1541301219238:blk_1073743402_2578 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 3406%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%DEBUG ResponseProcessor for block BP-593636016-192.168.157.1-1541301219238:blk_1073743402_2578 org.apache.hadoop.hdfs.DFSClient - DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0%DEBUG DataStreamer for file /TestResultOutput/_temporary/0/_temporary/attempt_local440030644_0001_r_000000_0/Class_CANA-r-00000 block BP-593636016-192.168.157.1-1541301219238:blk_1073743402_2578 org.apache.hadoop.hdfs.DFSClient - DataStreamer block BP-593636016-192.168.157.1-1541301219238:blk_1073743402_2578 sending packet packet seqno: 1 offsetInBlock: 3406 lastPacketInBlock: true lastByteOffsetInBlock: 3406%DEBUG ResponseProcessor for block BP-593636016-192.168.157.1-1541301219238:blk_1073743402_2578 org.apache.hadoop.hdfs.DFSClient - DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0%DEBUG DataStreamer for file /TestResultOutput/_temporary/0/_temporary/attempt_local440030644_0001_r_000000_0/Class_CANA-r-00000 block BP-593636016-192.168.157.1-1541301219238:blk_1073743402_2578 org.apache.hadoop.hdfs.DFSClient - Closing old block BP-593636016-192.168.157.1-1541301219238:blk_1073743402_2578%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #697%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #697%DEBUG pool-6-thread-1 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: complete took 15ms%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #698%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #698%DEBUG pool-6-thread-1 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: complete took 62ms%DEBUG pool-6-thread-1 org.apache.hadoop.hdfs.DFSClient - DFSClient writeChunk allocating new packet seqno=0, src=/TestResultOutput/_temporary/0/_temporary/attempt_local440030644_0001_r_000000_0/Class_AUSTR-r-00000, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0%DEBUG pool-6-thread-1 org.apache.hadoop.hdfs.DFSClient - Queued packet 0%DEBUG Thread-356 org.apache.hadoop.hdfs.DFSClient - Allocating new block%DEBUG pool-6-thread-1 org.apache.hadoop.hdfs.DFSClient - Queued packet 1%DEBUG pool-6-thread-1 org.apache.hadoop.hdfs.DFSClient - Waiting for ack for: 1%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #699%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #699%DEBUG Thread-356 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: addBlock took 63ms%DEBUG Thread-356 org.apache.hadoop.hdfs.DFSClient - pipeline = DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]%DEBUG Thread-356 org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 127.0.0.1:50010%DEBUG Thread-356 org.apache.hadoop.hdfs.DFSClient - Send buf size 131072%DEBUG Thread-356 org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient - SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]%DEBUG DataStreamer for file /TestResultOutput/_temporary/0/_temporary/attempt_local440030644_0001_r_000000_0/Class_AUSTR-r-00000 block BP-593636016-192.168.157.1-1541301219238:blk_1073743403_2579 org.apache.hadoop.hdfs.DFSClient - DataStreamer block BP-593636016-192.168.157.1-1541301219238:blk_1073743403_2579 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 4552%DEBUG ResponseProcessor for block BP-593636016-192.168.157.1-1541301219238:blk_1073743403_2579 org.apache.hadoop.hdfs.DFSClient - DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0%DEBUG DataStreamer for file /TestResultOutput/_temporary/0/_temporary/attempt_local440030644_0001_r_000000_0/Class_AUSTR-r-00000 block BP-593636016-192.168.157.1-1541301219238:blk_1073743403_2579 org.apache.hadoop.hdfs.DFSClient - DataStreamer block BP-593636016-192.168.157.1-1541301219238:blk_1073743403_2579 sending packet packet seqno: 1 offsetInBlock: 4552 lastPacketInBlock: true lastByteOffsetInBlock: 4552%DEBUG ResponseProcessor for block BP-593636016-192.168.157.1-1541301219238:blk_1073743403_2579 org.apache.hadoop.hdfs.DFSClient - DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0%DEBUG DataStreamer for file /TestResultOutput/_temporary/0/_temporary/attempt_local440030644_0001_r_000000_0/Class_AUSTR-r-00000 block BP-593636016-192.168.157.1-1541301219238:blk_1073743403_2579 org.apache.hadoop.hdfs.DFSClient - Closing old block BP-593636016-192.168.157.1-1541301219238:blk_1073743403_2579%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #700%INFO communication thread org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #700%DEBUG pool-6-thread-1 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: complete took 47ms%DEBUG pool-6-thread-1 org.apache.hadoop.hdfs.DFSClient - Waiting for ack for: -1%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #701%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #701%DEBUG pool-6-thread-1 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: complete took 32ms%INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local440030644_0001_r_000000_0 is done. And is in the process of committing%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #702%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #702%DEBUG pool-6-thread-1 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 15ms%INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce%INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local440030644_0001_r_000000_0 is allowed to commit now%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #703%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #703%DEBUG pool-6-thread-1 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 0ms%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #704%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #704%DEBUG pool-6-thread-1 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 0ms%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #705%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #705%DEBUG pool-6-thread-1 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: rename took 125ms%INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local440030644_0001_r_000000_0' to hdfs://localhost:9001/TestResultOutput/_temporary/0/task_local440030644_0001_r_000000%INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce%INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local440030644_0001_r_000000_0' done.%INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local440030644_0001_r_000000_0%INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #706%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #706%DEBUG Thread-4 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getListing took 16ms%DEBUG Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Merging data from FileStatus{path=hdfs://localhost:9001/TestResultOutput/_temporary/0/task_local440030644_0001_r_000000; isDirectory=true; modification_time=1544256748096; access_time=0; owner=root; group=supergroup; permission=rwxr-xr-x; isSymlink=false} to hdfs://localhost:9001/TestResultOutput%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #707%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #707%DEBUG Thread-4 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 0ms%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #708%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #708%DEBUG Thread-4 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getListing took 0ms%DEBUG Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Merging data from FileStatus{path=hdfs://localhost:9001/TestResultOutput/_temporary/0/task_local440030644_0001_r_000000/Class_AUSTR-r-00000; isDirectory=false; length=4552; replication=3; blocksize=134217728; modification_time=1544256751752; access_time=1544256748050; owner=root; group=supergroup; permission=rw-r--r--; isSymlink=false} to hdfs://localhost:9001/TestResultOutput/Class_AUSTR-r-00000%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #709%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #709%DEBUG Thread-4 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 0ms%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #710%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #710%DEBUG Thread-4 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: rename took 156ms%DEBUG Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Merging data from FileStatus{path=hdfs://localhost:9001/TestResultOutput/_temporary/0/task_local440030644_0001_r_000000/Class_CANA-r-00000; isDirectory=false; length=3406; replication=3; blocksize=134217728; modification_time=1544256751565; access_time=1544256748096; owner=root; group=supergroup; permission=rw-r--r--; isSymlink=false} to hdfs://localhost:9001/TestResultOutput/Class_CANA-r-00000%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #711%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #711%DEBUG Thread-4 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 0ms%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #712%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #712%DEBUG Thread-4 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: rename took 63ms%DEBUG Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Merging data from FileStatus{path=hdfs://localhost:9001/TestResultOutput/_temporary/0/task_local440030644_0001_r_000000/part-r-00000; isDirectory=false; length=0; replication=3; blocksize=134217728; modification_time=1544256751783; access_time=1544256747753; owner=root; group=supergroup; permission=rw-r--r--; isSymlink=false} to hdfs://localhost:9001/TestResultOutput/part-r-00000%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #713%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #713%DEBUG Thread-4 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 15ms%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #714%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #714%DEBUG Thread-4 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: rename took 50ms%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #715%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #715%DEBUG Thread-4 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: delete took 46ms%DEBUG Thread-4 org.apache.hadoop.hdfs.DFSClient - /TestResultOutput/_SUCCESS: masked=rw-r--r--%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #716%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #716%DEBUG Thread-4 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: create took 47ms%DEBUG Thread-4 org.apache.hadoop.hdfs.DFSClient - computePacketChunkSize: src=/TestResultOutput/_SUCCESS, chunkSize=516, chunksPerPacket=126, packetSize=65016%DEBUG Thread-4 org.apache.hadoop.hdfs.DFSClient - Waiting for ack for: -1%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root sending #717%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root got value #717%DEBUG Thread-4 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: complete took 47ms%DEBUG Thread-4 org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:670)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%INFO main org.apache.hadoop.mapreduce.Job - Job job_local440030644_0001 completed successfully%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.getCounters(Job.java:758)%INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=64370587
		FILE: Number of bytes written=56871895
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=54987628
		HDFS: Number of bytes written=7958
		HDFS: Number of read operations=74908
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=176
	Map-Reduce Framework
		Map input records=22339
		Map output records=22339
		Map output bytes=2962298
		Map output materialized bytes=24032
		Input split bytes=26084
		Combine input records=22339
		Combine output records=171
		Reduce input groups=171
		Reduce shuffle bytes=24032
		Reduce input records=171
		Reduce output records=0
		Spilled Records=342
		Shuffled Maps =171
		Failed Shuffles=0
		Merged Map outputs=171
		GC time elapsed (ms)=920
		Total committed heap usage (bytes)=175168815104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=212214
	File Output Format Counters 
		Bytes Written=0%DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)%DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@fba92d3%DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@fba92d3%DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@fba92d3%DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root: closed%DEBUG IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (1995250556) connection to localhost/127.0.0.1:9001 from root: stopped, remaining connections 0%DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)%DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)%DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)%DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics%DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty%DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object%DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...%DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library%DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution%DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping%DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000%DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login%DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit%DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "root" with name root%DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "root"%DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:root (auth:SIMPLE)%DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false%DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false%DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false%DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = %DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null%DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@5fd4f8f5%DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@247d8ae%DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.%DEBUG main org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection%DEBUG main org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.%DEBUG main org.apache.hadoop.ipc.Client - Connecting to localhost/127.0.0.1:9001%DEBUG IPC Client (63390) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (63390) connection to localhost/127.0.0.1:9001 from root: starting, having connections 1%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (63390) connection to localhost/127.0.0.1:9001 from root sending #0%DEBUG IPC Client (63390) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (63390) connection to localhost/127.0.0.1:9001 from root got value #0%DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getListing took 486ms%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (63390) connection to localhost/127.0.0.1:9001 from root sending #1%DEBUG IPC Client (63390) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (63390) connection to localhost/127.0.0.1:9001 from root got value #1%DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getListing took 16ms%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (63390) connection to localhost/127.0.0.1:9001 from root sending #2%DEBUG IPC Client (63390) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (63390) connection to localhost/127.0.0.1:9001 from root got value #2%DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getListing took 15ms%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (63390) connection to localhost/127.0.0.1:9001 from root sending #3%DEBUG IPC Client (63390) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (63390) connection to localhost/127.0.0.1:9001 from root got value #3%DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getListing took 16ms%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (63390) connection to localhost/127.0.0.1:9001 from root sending #4%DEBUG IPC Client (63390) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (63390) connection to localhost/127.0.0.1:9001 from root got value #4%DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 0ms%DEBUG main org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=4552
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743403_2579; getBlockSize()=4552; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743403_2579; getBlockSize()=4552; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG main org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 127.0.0.1:50010%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (63390) connection to localhost/127.0.0.1:9001 from root sending #5%DEBUG IPC Client (63390) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (63390) connection to localhost/127.0.0.1:9001 from root got value #5%DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getServerDefaults took 0ms%DEBUG main org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient - SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]%DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (63390) connection to localhost/127.0.0.1:9001 from root sending #6%DEBUG IPC Client (63390) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (63390) connection to localhost/127.0.0.1:9001 from root got value #6%DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 2ms%DEBUG main org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=3406
  underConstruction=false
  blocks=[LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743402_2578; getBlockSize()=3406; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-593636016-192.168.157.1-1541301219238:blk_1073743402_2578; getBlockSize()=3406; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]]}
  isLastBlockComplete=true}%DEBUG main org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 127.0.0.1:50010%DEBUG main org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient - SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-97473e0c-2141-4a26-8f72-d0859ea741f3,DISK]%DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@247d8ae%DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@247d8ae%DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@247d8ae%DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client%DEBUG IPC Client (63390) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (63390) connection to localhost/127.0.0.1:9001 from root: closed%DEBUG IPC Client (63390) connection to localhost/127.0.0.1:9001 from root org.apache.hadoop.ipc.Client - IPC Client (63390) connection to localhost/127.0.0.1:9001 from root: stopped, remaining connections 0%